{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_qNTzTy0jjWi"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "train_data_path = \"./data/train/audio/\"\n",
    "test_data_path = \"./data/test/audio/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N--LumPYmCho"
   },
   "outputs": [],
   "source": [
    "train_labels = 'yes no up down left right on off stop go silence unknown'.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lCmASp8jmLEJ"
   },
   "outputs": [],
   "source": [
    "def custom_fft(y, fs):\n",
    "    T = 1.0 / fs\n",
    "    N = y.shape[0]\n",
    "    yf = fft(y)\n",
    "    xf = np.linspace(0.0, 1.0/(2.0*T), N//2)\n",
    "    # FFT is simmetrical, so we take just the first half\n",
    "    # FFT is also complex, to we take just the real part (abs)\n",
    "    vals = 2.0/N * np.abs(yf[0:N//2])\n",
    "    return xf, vals\n",
    "\n",
    "def log_specgram(audio, sample_rate, window_size=20,\n",
    "                 step_size=10, eps=1e-10):\n",
    "    nperseg = int(round(window_size * sample_rate / 1e3))\n",
    "    noverlap = int(round(step_size * sample_rate / 1e3))\n",
    "    freqs, times, spec = signal.spectrogram(audio,\n",
    "                                    fs=sample_rate,\n",
    "                                    window='hann',\n",
    "                                    nperseg=nperseg,\n",
    "                                    noverlap=noverlap,\n",
    "                                    detrend=False)\n",
    "    return freqs, times, np.log(spec.T.astype(np.float32) + eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9k7qo0LcmPoq"
   },
   "outputs": [],
   "source": [
    "def list_wavs_fname_train(dirpath, ext='wav'):\n",
    "    print(dirpath)\n",
    "    fpaths = glob(os.path.join(dirpath, r'*/*' + ext))\n",
    "    pat = r'.+/(\\w+)/\\w+\\.' + ext + '$'\n",
    "    labels = []\n",
    "    for fpath in fpaths:\n",
    "        r = re.match(pat, fpath)\n",
    "        if r:\n",
    "            labels.append(r.group(1))\n",
    "    pat = r'.+/(\\w+\\.' + ext + ')$'\n",
    "    fnames = []\n",
    "    for fpath in fpaths:\n",
    "        r = re.match(pat, fpath)\n",
    "        if r:\n",
    "            fnames.append(r.group(1))\n",
    "    return labels, fnames\n",
    "\n",
    "def list_wavs_fname_test(dirpath, ext='wav'):\n",
    "    fnames = glob(os.path.join(dirpath, r'*' + ext))\n",
    "    return fnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bg05c2AymUky"
   },
   "outputs": [],
   "source": [
    "def pad_audio(samples):\n",
    "    if len(samples) >= L: return samples\n",
    "    else: return np.pad(samples, pad_width=(L - len(samples), 0), mode='constant', constant_values=(0, 0))\n",
    "\n",
    "def chop_audio(samples, L=16000, num=20):\n",
    "    for i in range(num):\n",
    "        beg = np.random.randint(0, len(samples) - L)\n",
    "        yield samples[beg: beg + L]\n",
    "\n",
    "def label_transform(labels):\n",
    "    nlabels = []\n",
    "    for label in labels:\n",
    "        if label == '_background_noise_':\n",
    "            nlabels.append('silence')\n",
    "        elif label not in train_labels:\n",
    "            nlabels.append('unknown')\n",
    "        else:\n",
    "            nlabels.append(label)\n",
    "    return nlabels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Importing train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import gc\n",
    "import re\n",
    "from scipy.io import wavfile\n",
    "from scipy import signal\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/train/audio/\n"
     ]
    }
   ],
   "source": [
    "labels, fnames = list_wavs_fname_train(train_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "MeVo2dy-mWcZ",
    "outputId": "af8a94a3-639d-4c2d-e395-629b53611419"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krzysztof/.conda/envs/ml-gpu/lib/python3.7/site-packages/ipykernel_launcher.py:7: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_background_noise_\n",
      "_background_noise_\n",
      "_background_noise_\n",
      "_background_noise_\n",
      "_background_noise_\n",
      "_background_noise_\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "293"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = 16000\n",
    "new_sample_rate = 8000\n",
    "y_train = []\n",
    "x_train = []\n",
    "\n",
    "for label, fname in zip(labels, fnames):\n",
    "    sample_rate, samples = wavfile.read(os.path.join(train_data_path, label, fname))\n",
    "    samples = pad_audio(samples)\n",
    "    if len(samples) > 16000:\n",
    "        n_samples = chop_audio(samples)\n",
    "        print(label)\n",
    "    else: n_samples = [samples]\n",
    "    for samples in n_samples:\n",
    "        resampled = signal.resample(samples, int(new_sample_rate / sample_rate * samples.shape[0]))\n",
    "        _, _, specgram = log_specgram(resampled, sample_rate=new_sample_rate)\n",
    "        y_train.append(label)\n",
    "        x_train.append(specgram)\n",
    "x_train = np.array(x_train)\n",
    "x_train = x_train.reshape(tuple(list(x_train.shape)))\n",
    "\n",
    "ohc = OneHotEncoder()\n",
    "y_train = label_transform(y_train)\n",
    "\n",
    "y_train = np.array(y_train).reshape(-1, 1)\n",
    "\n",
    "ohc.fit(y_train)\n",
    "\n",
    "y_train = ohc.transform(y_train)\n",
    "\n",
    "y_train = y_train.toarray()\n",
    "\n",
    "del labels, fnames\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UKU2jHSkxhWx"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers, losses, activations, models, layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "#import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 958
    },
    "colab_type": "code",
    "id": "CWtCKrZbmdq1",
    "outputId": "89d90c79-d6ab-44a9-dc2f-abd106094f7c"
   },
   "outputs": [],
   "source": [
    "input_shape = (99, 81)\n",
    "nclass = 12\n",
    "inp = layers.Input(shape=input_shape)\n",
    "norm_inp = layers.BatchNormalization()(inp)\n",
    "lstm = layers.Bidirectional(layers.CuDNNGRU(128, return_sequences=True))(norm_inp)\n",
    "lstm = layers.GlobalMaxPooling1D()(lstm)\n",
    "dense_1 = layers.Dense(128, activation=activations.relu)(lstm)\n",
    "dense_out = layers.Dense(nclass, activation=activations.softmax)(dense_1)\n",
    "\n",
    "model = models.Model(inputs=inp, outputs=dense_out)\n",
    "opt = optimizers.Adam()\n",
    "\n",
    "model.compile(optimizer=opt, loss=losses.binary_crossentropy, metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=4, shuffle=True)\n",
    "\n",
    "model.save(os.path.join('./models', 'LSTM_model_1'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Cleaning memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122776"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del x_train, y_train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Importing test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = list_wavs_fname_test(test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = 16000\n",
    "new_sample_rate = 8000\n",
    "x_test = []\n",
    "\n",
    "for fname in fnames:\n",
    "    sample_rate, samples = wavfile.read(fname)\n",
    "    samples = pad_audio(samples)\n",
    "    if len(samples) > 16000:\n",
    "        n_samples = chop_audio(samples)\n",
    "    else: n_samples = [samples]\n",
    "    for samples in n_samples:\n",
    "        resampled = signal.resample(samples, int(new_sample_rate / sample_rate * samples.shape[0]))\n",
    "        _, _, specgram = log_specgram(resampled, sample_rate=new_sample_rate)\n",
    "        x_test.append(specgram)\n",
    "x_test = np.array(x_test)\n",
    "x_test = x_test.reshape(tuple(list(x_test.shape)))\n",
    "del fnames\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "703"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del x_test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = list_wavs_fname_test(test_data_path)\n",
    "filenames = [x.split('/')[-1] for x in fnames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ohc.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_df['fname'] = filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_df['label'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_df.to_csv('kaggle_lstm_1.csv', index=False, header=True, quoting=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['down', 'go', 'left', 'no', 'off', 'on', 'right', 'silence',\n",
       "        'stop', 'unknown', 'up', 'yes'], dtype='<U7'),\n",
       " array([  3470,   6608,   4083,   6474,   7022,   6025,   6100,   2171,\n",
       "          4090, 104078,   3667,   4750]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_pred, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "deep-learning-methods-project-3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (ml-gpu)",
   "language": "python",
   "name": "ml-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
